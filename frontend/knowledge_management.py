import os
import requests
import streamlit as st
from dotenv import load_dotenv
from datetime import datetime
import time
from typing import Dict, List, Optional
import json

load_dotenv(override=True)

st.set_page_config(
    page_title="çŸ¥è¯†åº“ç®¡ç†",
    page_icon="ğŸ“š",
    layout="wide"
)

API_URL = os.getenv("API_URL", "http://localhost:8000")
EMBEDDING_CONFIG_FILE = "embedding_config.json"

EMBEDDING_MODEL_PROVIDERS = {
    "OpenAI": {
        "name": "OpenAI",
        "api_key_env": "OPENAI_API_KEY",
        "base_url_env": "OPENAI_BASE_URL",
        "default_base_url": "https://api.openai.com/v1",
        "models": [
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002"
        ],
        "requires_base_url": False
    },
    "AzureOpenAI": {
        "name": "Azure OpenAI",
        "api_key_env": "AZURE_OPENAI_API_KEY",
        "endpoint_env": "AZURE_OPENAI_ENDPOINT",
        "deployment_env": "AZURE_OPENAI_EMBEDDING_DEPLOYMENT",
        "api_version_env": "AZURE_OPENAI_API_VERSION",
        "default_api_version": "2024-02-15-preview",
        "models": [
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002"
        ],
        "requires_endpoint": True
    },
    "ç¡…åŸºæµåŠ¨": {
        "name": "ç¡…åŸºæµåŠ¨",
        "api_key_env": "SILICONFLOW_API_KEY",
        "base_url_env": "SILICONFLOW_BASE_URL",
        "default_base_url": "https://api.siliconflow.cn/v1",
        "models": [
            "BAAI/bge-large-zh-v1.5",
            "BAAI/bge-base-zh-v1.5",
            "BAAI/bge-small-zh-v1.5",
            "BAAI/bge-m3",
            "sentence-transformers/all-MiniLM-L6-v2"
        ],
        "requires_base_url": False
    },
    "é˜¿é‡Œç™¾ç‚¼": {
        "name": "é˜¿é‡Œç™¾ç‚¼",
        "api_key_env": "DASHSCOPE_API_KEY",
        "base_url_env": "DASHSCOPE_BASE_URL",
        "default_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "models": [
            "text-embedding-v3",
            "text-embedding-v2",
            "text-embedding-async-v2"
        ],
        "requires_base_url": False
    },
    "DeepSeek": {
        "name": "DeepSeek",
        "api_key_env": "DEEPSEEK_API_KEY",
        "base_url_env": "DEEPSEEK_BASE_URL",
        "default_base_url": "https://api.deepseek.com/v1",
        "models": [
            "deepseek-embeddings"
        ],
        "requires_base_url": False
    }
}

def format_file_size(size_bytes):
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.2f} KB"
    else:
        return f"{size_bytes / (1024 * 1024):.2f} MB"

def format_upload_time(upload_time):
    try:
        dt = datetime.fromisoformat(upload_time)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return upload_time

def validate_embedding_config(provider: str, api_key: str, base_url: Optional[str] = None, endpoint: Optional[str] = None, api_version: Optional[str] = None) -> tuple[bool, str]:
    try:
        provider_config = EMBEDDING_MODEL_PROVIDERS[provider]
        
        if not api_key:
            return False, f"{provider_config['name']} API Key ä¸èƒ½ä¸ºç©º"
        
        if provider == "AzureOpenAI":
            if not endpoint:
                return False, "Azure OpenAI Endpoint ä¸èƒ½ä¸ºç©º"
            if not api_version:
                return False, "Azure OpenAI API Version ä¸èƒ½ä¸ºç©º"
        else:
            if provider_config.get("requires_base_url", False) and not base_url:
                return False, f"{provider_config['name']} Base URL ä¸èƒ½ä¸ºç©º"
        
        return True, "é…ç½®éªŒè¯é€šè¿‡"
    except Exception as e:
        return False, f"éªŒè¯å¤±è´¥: {str(e)}"

def test_embedding_connection(provider: str, model: str, api_key: str, base_url: Optional[str] = None, endpoint: Optional[str] = None, api_version: Optional[str] = None) -> tuple[bool, str]:
    try:
        if provider == "AzureOpenAI":
            url = f"{endpoint.rstrip('/')}/openai/deployments/{model}/embeddings?api-version={api_version}"
            headers = {"api-key": api_key, "Content-Type": "application/json"}
            payload = {
                "input": "test"
            }
        else:
            url = f"{base_url.rstrip('/')}/embeddings"
            headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
            payload = {
                "model": model,
                "input": "test"
            }
        
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            return True, "è¿æ¥æµ‹è¯•æˆåŠŸ"
        elif response.status_code == 401:
            return False, "API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ"
        elif response.status_code == 404:
            return False, "æ¨¡å‹ä¸å­˜åœ¨æˆ–æœªéƒ¨ç½²"
        elif response.status_code == 429:
            return False, "è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•"
        else:
            error_data = response.json() if response.headers.get("content-type", "").startswith("application/json") else {}
            error_msg = error_data.get("error", {}).get("message", f"HTTP {response.status_code}")
            return False, f"è¿æ¥å¤±è´¥: {error_msg}"
    except requests.exceptions.Timeout:
        return False, "è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡åœ°å€"
    except requests.exceptions.ConnectionError:
        return False, "æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡åœ°å€"
    except Exception as e:
        return False, f"æµ‹è¯•è¿æ¥æ—¶å‡ºé”™: {str(e)}"

def fetch_embedding_models(provider: str, api_key: str, base_url: Optional[str] = None, endpoint: Optional[str] = None, api_version: Optional[str] = None) -> tuple[bool, List[str], str]:
    try:
        if provider == "AzureOpenAI":
            url = f"{endpoint.rstrip('/')}/openai/deployments?api-version={api_version}"
            headers = {"api-key": api_key}
        else:
            url = f"{base_url.rstrip('/')}/models"
            headers = {"Authorization": f"Bearer {api_key}"}
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            if provider == "AzureOpenAI":
                models = [deployment.get("model", deployment.get("id", "")) for deployment in data.get("data", [])]
            else:
                models = [model.get("id", "") for model in data.get("data", [])]
            
            models = [m for m in models if m]
            
            if models:
                return True, models, f"æˆåŠŸè·å– {len(models)} ä¸ªæ¨¡å‹"
            else:
                return False, [], "æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹"
        else:
            return False, [], f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}"
    except Exception as e:
        return False, [], f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}"

def save_embedding_config(config: Dict):
    try:
        with open(EMBEDDING_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True, "é…ç½®å·²ä¿å­˜"
    except Exception as e:
        return False, f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}"

def load_embedding_config() -> Optional[Dict]:
    try:
        if os.path.exists(EMBEDDING_CONFIG_FILE):
            with open(EMBEDDING_CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    except Exception:
        return None

@st.cache_resource(ttl=60)
def get_documents():
    try:
        response = requests.get(f"{API_URL}/documents", timeout=10)
        if response.status_code == 200:
            return response.json()
        return []
    except:
        return []

def delete_document(document_id):
    try:
        response = requests.delete(f"{API_URL}/documents/{document_id}", timeout=10)
        if response.status_code == 200:
            get_documents.clear()
            return True
        return False
    except:
        return False

def upload_document(file, chunk_size=500, overlap=50, embedding_config=None):
    try:
        files = {"file": (file.name, file, file.type)}
        data = {"chunk_size": chunk_size, "overlap": overlap}
        if embedding_config:
            data["embedding_config"] = embedding_config
        response = requests.post(f"{API_URL}/upload", files=files, data=data, timeout=60)
        if response.status_code == 200:
            get_documents.clear()
            return response.json()
        return {"success": False, "error": "ä¸Šä¼ å¤±è´¥"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def render_embedding_config_sidebar():
    st.sidebar.markdown("### ğŸ”¤ åµŒå…¥æ¨¡å‹é…ç½®")
    
    if "embedding_config" not in st.session_state:
        saved_config = load_embedding_config()
        if saved_config:
            st.session_state.embedding_config = saved_config
        else:
            st.session_state.embedding_config = {
                "provider": "OpenAI",
                "model": "text-embedding-3-small",
                "api_key": "",
                "base_url": "",
                "endpoint": "",
                "api_version": ""
            }
    
    provider_options = list(EMBEDDING_MODEL_PROVIDERS.keys())
    provider_display = [EMBEDDING_MODEL_PROVIDERS[p]["name"] for p in provider_options]
    
    selected_provider_display = st.sidebar.selectbox(
        "é€‰æ‹©åµŒå…¥ä¾›åº”å•†",
        options=provider_display,
        index=provider_options.index(st.session_state.embedding_config["provider"]),
        help="é€‰æ‹©è¦ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹ä¾›åº”å•†"
    )
    
    selected_provider = provider_options[provider_display.index(selected_provider_display)]
    
    if st.session_state.embedding_config["provider"] != selected_provider:
        st.session_state.embedding_config["provider"] = selected_provider
        provider_config = EMBEDDING_MODEL_PROVIDERS[selected_provider]
        api_key_env_value = os.getenv(provider_config["api_key_env"], "")
        st.session_state.embedding_config["api_key"] = api_key_env_value
        if selected_provider == "AzureOpenAI":
            endpoint_env_value = os.getenv(provider_config["endpoint_env"], "")
            api_version_env_value = os.getenv(provider_config["api_version_env"], "")
            deployment_env_value = os.getenv(provider_config["deployment_env"], "")
            st.session_state.embedding_config["endpoint"] = endpoint_env_value
            st.session_state.embedding_config["api_version"] = api_version_env_value or provider_config["default_api_version"]
            st.session_state.embedding_config["deployment"] = deployment_env_value
            st.session_state.embedding_config["base_url"] = ""
        else:
            base_url_env_value = os.getenv(provider_config.get("base_url_env", ""), "")
            st.session_state.embedding_config["base_url"] = base_url_env_value or provider_config.get("default_base_url", "")
            st.session_state.embedding_config["endpoint"] = ""
            st.session_state.embedding_config["api_version"] = ""
            st.session_state.embedding_config["deployment"] = ""
        st.session_state.embedding_config["model"] = provider_config["models"][0]
        st.rerun()
    
    provider_config = EMBEDDING_MODEL_PROVIDERS[selected_provider]
    
    st.sidebar.caption(f"å½“å‰ä¾›åº”å•†: {provider_config['name']}")
    
    api_key_env_value = os.getenv(provider_config["api_key_env"], "")
    api_key = st.sidebar.text_input(
        "API Key",
        value=st.session_state.embedding_config.get("api_key") or api_key_env_value,
        type="password",
        help=f"è¾“å…¥ {provider_config['name']} çš„ API Keyï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ {provider_config['api_key_env']} é…ç½®ï¼‰"
    )
    st.session_state.embedding_config["api_key"] = api_key
    
    if selected_provider == "AzureOpenAI":
        endpoint_env_value = os.getenv(provider_config["endpoint_env"], "")
        endpoint = st.sidebar.text_input(
            "Endpoint",
            value=st.session_state.embedding_config.get("endpoint") or endpoint_env_value,
            help="Azure OpenAI æœåŠ¡ç«¯ç‚¹ï¼Œä¾‹å¦‚: https://your-resource.openai.azure.com"
        )
        st.session_state.embedding_config["endpoint"] = endpoint
        
        api_version_env_value = os.getenv(provider_config["api_version_env"], "")
        api_version = st.sidebar.text_input(
            "API Version",
            value=st.session_state.embedding_config.get("api_version") or api_version_env_value or provider_config["default_api_version"],
            help="Azure OpenAI API ç‰ˆæœ¬"
        )
        st.session_state.embedding_config["api_version"] = api_version
        
        deployment_env_value = os.getenv(provider_config["deployment_env"], "")
        deployment = st.sidebar.text_input(
            "éƒ¨ç½²åç§° (å¯é€‰)",
            value=st.session_state.embedding_config.get("deployment") or deployment_env_value,
            help="Azure OpenAI éƒ¨ç½²åç§°ï¼ˆå¦‚æœä¸æ¨¡å‹åç§°ä¸åŒï¼‰"
        )
        st.session_state.embedding_config["deployment"] = deployment
    else:
        base_url_env_value = os.getenv(provider_config.get("base_url_env", ""), "")
        base_url = st.sidebar.text_input(
            "Base URL (å¯é€‰)",
            value=st.session_state.embedding_config.get("base_url") or base_url_env_value or provider_config.get("default_base_url", ""),
            help=f"{provider_config['name']} API çš„ Base URLï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤å€¼ï¼‰"
        )
        st.session_state.embedding_config["base_url"] = base_url
    
    available_models = provider_config["models"]
    
    # if st.sidebar.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", key="refresh_embedding_models"):
    #     with st.spinner("æ­£åœ¨è·å–åµŒå…¥æ¨¡å‹åˆ—è¡¨..."):
    #         if selected_provider == "AzureOpenAI":
    #             success, models, message = fetch_embedding_models(
    #                 selected_provider, api_key,
    #                 endpoint=st.session_state.embedding_config.get("endpoint"),
    #                 api_version=st.session_state.embedding_config.get("api_version")
    #             )
    #         else:
    #             success, models, message = fetch_embedding_models(
    #                 selected_provider, api_key,
    #                 base_url=st.session_state.embedding_config.get("base_url")
    #             )
            
    #         if success:
    #             st.sidebar.success(f"âœ“ {message}")
    #             if models:
    #                 EMBEDDING_MODEL_PROVIDERS[selected_provider]["models"] = models
    #                 st.session_state.embedding_config["model"] = models[0]
    #                 st.rerun()
    #         else:
    #             st.sidebar.error(f"âœ— {message}")
    
    if st.session_state.embedding_config["model"] not in available_models:
        st.session_state.embedding_config["model"] = available_models[0]
    
    selected_model = st.sidebar.selectbox(
        "é€‰æ‹©åµŒå…¥æ¨¡å‹",
        options=available_models,
        index=available_models.index(st.session_state.embedding_config["model"]),
        help=f"é€‰æ‹© {provider_config['name']} çš„å…·ä½“åµŒå…¥æ¨¡å‹"
    )
    st.session_state.embedding_config["model"] = selected_model
    
    col1, col2, col3 = st.sidebar.columns(3)
    with col1:
        if st.sidebar.button("âœ… éªŒè¯", use_container_width=True, key="validate_embedding"):
            is_valid, message = validate_embedding_config(
                selected_provider,
                api_key,
                base_url=st.session_state.embedding_config.get("base_url"),
                endpoint=st.session_state.embedding_config.get("endpoint"),
                api_version=st.session_state.embedding_config.get("api_version")
            )
            if is_valid:
                st.sidebar.success(f"âœ“ {message}")
            else:
                st.sidebar.error(f"âœ— {message}")
    
    with col2:
        if st.sidebar.button("ğŸ”— æµ‹è¯•", use_container_width=True, key="test_embedding"):
            is_valid, _ = validate_embedding_config(
                selected_provider,
                api_key,
                base_url=st.session_state.embedding_config.get("base_url"),
                endpoint=st.session_state.embedding_config.get("endpoint"),
                api_version=st.session_state.embedding_config.get("api_version")
            )
            if not is_valid:
                st.sidebar.error("âœ— è¯·å…ˆå®Œæˆé…ç½®éªŒè¯")
            else:
                with st.spinner("æ­£åœ¨æµ‹è¯•åµŒå…¥è¿æ¥..."):
                    if selected_provider == "AzureOpenAI":
                        success, message = test_embedding_connection(
                            selected_provider, selected_model, api_key,
                            endpoint=st.session_state.embedding_config.get("endpoint"),
                            api_version=st.session_state.embedding_config.get("api_version")
                        )
                    else:
                        success, message = test_embedding_connection(
                            selected_provider, selected_model, api_key,
                            base_url=st.session_state.embedding_config.get("base_url")
                        )
                    if success:
                        st.sidebar.success(f"âœ“ {message}")
                    else:
                        st.sidebar.error(f"âœ— {message}")
    
    with col3:
        if st.sidebar.button("ğŸ’¾ ä¿å­˜", use_container_width=True, key="save_embedding"):
            success, message = save_embedding_config(st.session_state.embedding_config)
            if success:
                st.sidebar.success(f"âœ“ {message}")
            else:
                st.sidebar.error(f"âœ— {message}")
    
    st.sidebar.divider()
    
    return st.session_state.embedding_config

st.title("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")

st.sidebar.title("âš™ï¸ è®¾ç½®")

embedding_config = render_embedding_config_sidebar()

is_embedding_config_valid, _ = validate_embedding_config(
    embedding_config["provider"],
    embedding_config.get("api_key", ""),
    base_url=embedding_config.get("base_url"),
    endpoint=embedding_config.get("endpoint"),
    api_version=embedding_config.get("api_version")
)

if not is_embedding_config_valid:
    st.warning("âš ï¸ åµŒå…¥æ¨¡å‹é…ç½®ä¸å®Œæ•´ï¼Œè¯·åœ¨ä¾§è¾¹æ å®Œæˆé…ç½®åä¸Šä¼ æ–‡æ¡£")

st.markdown("""
<div style="padding: 10px; background-color: #e8f5e9; border-radius: 5px; margin-bottom: 20px;">
    <strong>ğŸ“– çŸ¥è¯†åº“è¯´æ˜ï¼š</strong>åœ¨æ­¤é¡µé¢ç®¡ç†æ‚¨çš„æ–‡æ¡£ï¼Œä¸Šä¼ çš„æ–‡æ¡£å°†è¢«å¤„ç†å¹¶å­˜å‚¨åˆ°çŸ¥è¯†åº“ä¸­ï¼Œä¾›AIå¯¹è¯æ—¶æ£€ç´¢ä½¿ç”¨ã€‚
</div>
""", unsafe_allow_html=True)

col1, col2 = st.columns([1, 2])

documents_placeholder = st.empty()
documents = get_documents()

with col1:
    st.subheader("ğŸ“ ä¸Šä¼ æ–‡æ¡£")
    
    st.markdown("#### âš™ï¸ æ–‡æœ¬åˆ†å‰²è®¾ç½®")
    col_chunk, col_overlap = st.columns(2)
    with col_chunk:
        chunk_size = st.slider(
            "æ–‡æœ¬å—å¤§å°",
            min_value=100,
            max_value=2000,
            value=500,
            step=50,
            help="æ¯ä¸ªæ–‡æœ¬å—åŒ…å«çš„å­—ç¬¦æ•°"
        )
    with col_overlap:
        overlap = st.slider(
            "é‡å å—å¤§å°",
            min_value=0,
            max_value=500,
            value=50,
            step=10,
            help="ç›¸é‚»æ–‡æœ¬å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°"
        )
    st.caption("ğŸ’¡ è¾ƒå°çš„æ–‡æœ¬å—å¯ä»¥æé«˜æ£€ç´¢ç²¾åº¦ï¼Œè¾ƒå¤§çš„æ–‡æœ¬å—å¯ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡")
    st.divider()
    
    if "uploaded_files_cache" not in st.session_state:
        st.session_state.uploaded_files_cache = []
    
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡æ¡£",
        type=["pdf", "txt", "docx", "xlsx"],
        accept_multiple_files=True,
        help="æ”¯æŒ PDFã€TXTã€DOCXã€XLSX æ ¼å¼çš„æ–‡æ¡£",
        key="file_uploader"
    )
    
    if st.button("ğŸ”„ æ¸…é™¤ä¸Šä¼ ç¼“å­˜", key="clear_cache"):
        st.session_state.uploaded_files_cache = []
        st.success("ç¼“å­˜å·²æ¸…é™¤ï¼Œå¯ä»¥é‡æ–°ä¸Šä¼ æ–‡ä»¶")
        st.rerun()
    
    if uploaded_files:
        new_files = []
        for uploaded_file in uploaded_files:
            file_key = f"{uploaded_file.name}_{uploaded_file.size}"
            if file_key not in st.session_state.uploaded_files_cache:
                new_files.append(uploaded_file)
        
        if new_files:
            for uploaded_file in new_files:
                with st.spinner(f"æ­£åœ¨å¤„ç† {uploaded_file.name}..."):
                    result = upload_document(uploaded_file, chunk_size, overlap, embedding_config)
                    file_key = f"{uploaded_file.name}_{uploaded_file.size}"
                    st.session_state.uploaded_files_cache.append(file_key)
                    if result.get("success"):
                        st.success(f"âœ… {uploaded_file.name} ä¸Šä¼ æˆåŠŸï¼ç”Ÿæˆ {result.get('chunks_count', 0)} ä¸ªçŸ¥è¯†å—")
                    else:
                        error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                        if "æå–çš„æ–‡æœ¬å†…å®¹ä¸ºç©º" in error_msg:
                            error_msg += "\nğŸ’¡ æç¤ºï¼šè¯¥æ–‡ä»¶å¯èƒ½æ˜¯å›¾ç‰‡å‹PDFï¼Œè¯·ä½¿ç”¨å¯æå–æ–‡æœ¬çš„PDFæˆ–è½¬æ¢ä¸ºTXTæ ¼å¼"
                        st.error(f"âŒ {uploaded_file.name} ä¸Šä¼ å¤±è´¥: {error_msg}")
            st.rerun()
    
    st.divider()
    
    st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    documents = get_documents()
    
    total_docs = len(documents)
    completed_docs = sum(1 for doc in documents if doc.get('status') == 'completed')
    total_chunks = sum(doc.get('chunks_count', 0) for doc in documents if doc.get('status') == 'completed')
    
    col_a, col_b, col_c = st.columns(3)
    with col_a:
        st.metric("æ€»æ–‡æ¡£æ•°", total_docs)
    with col_b:
        st.metric("å·²å¤„ç†æ–‡æ¡£", completed_docs)
    with col_c:
        st.metric("çŸ¥è¯†å—æ€»æ•°", total_chunks)

with documents_placeholder.container():
    with col2:
        st.subheader(f"ğŸ“„ å·²ä¸Šä¼ æ–‡æ¡£ ({len(documents)})")
        
        if documents:
            for doc in documents:
                status_emoji = "âœ…" if doc['status'] == 'completed' else "â³" if doc['status'] == 'processing' else "âŒ"
                status_text = "å·²å¤„ç†" if doc['status'] == 'completed' else "å¤„ç†ä¸­" if doc['status'] == 'processing' else "å¤±è´¥"
                
                with st.expander(f"{status_emoji} {doc['filename']}", expanded=False):
                    col_a, col_b = st.columns([3, 1])
                    
                    with col_a:
                        st.write(f"**ä¸Šä¼ æ—¶é—´:** {format_upload_time(doc['upload_time'])}")
                        st.write(f"**æ–‡ä»¶å¤§å°:** {format_file_size(doc['file_size'])}")
                        st.write(f"**æ–‡ä»¶ç±»å‹:** {doc['file_type']}")
                        if doc.get('status') == 'completed':
                            st.write(f"**çŸ¥è¯†å—æ•°é‡:** {doc.get('chunks_count', 0)}")
                        st.write(f"**çŠ¶æ€:** {status_text}")
                    
                    with col_b:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{doc['id']}"):
                            st.session_state[f"confirm_delete_{doc['id']}"] = True
                    
                    if st.session_state.get(f"confirm_delete_{doc['id']}", False):
                        st.warning(f"âš ï¸ ç¡®è®¤è¦åˆ é™¤æ–‡æ¡£ '{doc['filename']}' å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ã€‚")
                        col_c, col_d = st.columns([1, 1])
                        with col_c:
                            if st.button("âœ… ç¡®è®¤åˆ é™¤", key=f"confirm_{doc['id']}", type="primary"):
                                with st.spinner("æ­£åœ¨åˆ é™¤..."):
                                    time.sleep(0.3)
                                    if delete_document(doc['id']):
                                        st.success("æ–‡æ¡£åˆ é™¤æˆåŠŸ")
                                        del st.session_state[f"confirm_delete_{doc['id']}"]
                                        st.rerun()
                                    else:
                                        st.error("æ–‡æ¡£åˆ é™¤å¤±è´¥")
                        with col_d:
                            if st.button("âŒ å–æ¶ˆ", key=f"cancel_{doc['id']}"):
                                del st.session_state[f"confirm_delete_{doc['id']}"]
                                st.rerun()
        else:
            st.info("ğŸ“­ æš‚æ— æ–‡æ¡£ï¼Œè¯·ä¸Šä¼ æ–‡æ¡£å¼€å§‹ä½¿ç”¨çŸ¥è¯†åº“")

st.sidebar.divider()
st.sidebar.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("""
1. **åµŒå…¥æ¨¡å‹é…ç½®**: 
   - é€‰æ‹©åµŒå…¥æ¨¡å‹ä¾›åº”å•†ï¼ˆOpenAIã€AzureOpenAIã€ç¡…åŸºæµåŠ¨ã€é˜¿é‡Œç™¾ç‚¼ã€DeepSeekï¼‰
   - é…ç½®API Keyå’Œç›¸å…³å‚æ•°
   - éªŒè¯é…ç½®å¹¶æµ‹è¯•è¿æ¥
   - ä¿å­˜é…ç½®ä»¥ä¾›åç»­ä½¿ç”¨
2. **ä¸Šä¼ æ–‡æ¡£**: æ”¯æŒä¸Šä¼  PDFã€TXTã€DOCX æ ¼å¼çš„æ–‡æ¡£
3. **æ–‡æœ¬åˆ†å‰²è®¾ç½®**: 
   - æ–‡æœ¬å—å¤§å°ï¼šæ¯ä¸ªçŸ¥è¯†å—åŒ…å«çš„å­—ç¬¦æ•°ï¼ˆ100-2000ï¼‰
   - é‡å å—å¤§å°ï¼šç›¸é‚»å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼ˆ0-500ï¼‰
   - è¾ƒå°çš„æ–‡æœ¬å—å¯æé«˜æ£€ç´¢ç²¾åº¦ï¼Œè¾ƒå¤§çš„æ–‡æœ¬å—æä¾›æ›´å¤šä¸Šä¸‹æ–‡
4. **æ–‡æ¡£å¤„ç†**: ç³»ç»Ÿä¼šä½¿ç”¨é…ç½®çš„åµŒå…¥æ¨¡å‹å°†æ–‡æ¡£å†…å®¹å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°çŸ¥è¯†åº“
5. **çŸ¥è¯†å—ç”Ÿæˆ**: æ–‡æ¡£ä¼šè¢«åˆ†å‰²æˆå¤šä¸ªçŸ¥è¯†å—ï¼Œä¾¿äºæ£€ç´¢
6. **åˆ é™¤æ–‡æ¡£**: å¯ä»¥åˆ é™¤ä¸éœ€è¦çš„æ–‡æ¡£ï¼ŒåŒæ—¶æ¸…é™¤ç›¸å…³çŸ¥è¯†å—
7. **å¯¹è¯ä½¿ç”¨**: åœ¨AIå¯¹è¯é¡µé¢æé—®æ—¶ï¼Œç³»ç»Ÿä¼šæ£€ç´¢æ­¤çŸ¥è¯†åº“ä¸­çš„å†…å®¹
""")
